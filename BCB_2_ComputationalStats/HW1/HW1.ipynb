{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><a id='outline'>Project Outline</a></h1>\n",
    "\n",
    "* [Data Pre-Processing](#dpp)\n",
    "  *  [Required Libraries](#libs)\n",
    "  *  [Separate Data](#sep)\n",
    "  *  [General Data Overview](#gdo)\n",
    "* [Question 1](#rq1d)\n",
    "  *  [Read in Q1 Data](#rq1d)\n",
    "  *  [Quality Score Distribution](#sep)\n",
    "  *  [Separate Data](#sep)\n",
    "  *  [Question 1a](#q1a)\n",
    "  *  [Question 1b Code](#q1bc)\n",
    "  *  [Question 1b Answer](#q1ba)\n",
    "  *  [Question 1c Code](#q1cc)\n",
    "  *  [Question 1c Answer](#q1ca)\n",
    "  *  [Question 1d](#q1d)\n",
    "  *  [Question 1e](#q1e)\n",
    "* [Question 2](#q2cc)\n",
    "  * [Question 2 Code](#q2cc)\n",
    "  * [Question 2 Answer](#q2ab)\n",
    "  * [Question 2c](#q2c)\n",
    "* [Question 3](#q3)\n",
    "    * [Identify all the sites whose support for homozygosity is high](#q3)\n",
    "    * [Aggregate the data](#q3g)\n",
    "    * [Question 3a](#q3a)\n",
    "      * [Estimate $\\hat{P_q}$ for all q](#q3pq)\n",
    "      * [Calculate $L(H_o |  Data )$ using $\\hat{P}_{q}$ values](#q3lho)\n",
    "      * [Estimate $\\hat{P_{bq}}$ for all q and all true bases b](#q3pqb)\n",
    "      * [Calculate $L(H_a |  Data )$ using $\\hat{P}_{qb}$ values](#q3lha)\n",
    "      * [Calculate the P-Val for the LRT](#q3pval)\n",
    "    * [Question 3b](#q3b)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"dpp\">Data prep and cursory analysis</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id=\"libs\">Python Libraries and Jupyter Magic</a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "# if the line above fails then in the command line type: conda install -c r rpy2; conda install tzlocal\n",
    "#After installing restart your kernal by clicking Kernal -> restart\n",
    "from pandas import Series\n",
    "from collections import Counter\n",
    "from Locus import *\n",
    "from math import log\n",
    "from os import chdir\n",
    "from rpy2.robjects.packages import STAP\n",
    "from rpy2.robjects.vectors import FloatVector as rArray\n",
    "from scipy.stats import chi2\n",
    "from sys import maxsize as MAXSIZE\n",
    "import rpy2.rinterface\n",
    "import pickle\n",
    "\n",
    "chdir(\"/mnt/research/germs/shane/Classes/BCB_2_ComputationalStats/HW1\") #comment this line out if you aren't Shane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate Data\n",
    "<a id=\"sep\"></a>\n",
    "##### Divide the data by individual and position because github wont allow large files and this will allow us to only load small amounts of data into memory at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/\n",
    "for individual in {0..2}; do \n",
    "    for pos in {764..1199}; do\n",
    "        awk -v individual=\"$individual\" -v pos=\"$pos\" '($1==individual && $3==pos && $4!=\"NA\") {print $0}' genotyping.txt > Individual$individual\\_position$pos.txt\n",
    "    done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Data Overview \n",
    "<a id=\"gdo\"></a>\n",
    "<ol style=\"display: inline; padding: 0;margin-top: -10px;\"> <p style=\"display: inline; padding: 0;margin-top: -10px;\"><u>Genotyping.txt Column Designations:</u></p>\n",
    "    <li>Id of individual</li>\n",
    "    <li>Id of read</li>\n",
    "    <li>Reference position</li>\n",
    "    <li>Read base call</li>\n",
    "    <li>Read quality score</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 962 A p\n",
      "0 1 962 A h\n",
      "0 2 962 A i\n",
      "0 3 962 A l\n",
      "0 4 962 G X\n",
      "0 5 962 G p\n",
      "0 6 962 G p\n",
      "0 7 962 A p\n",
      "0 8 962 A p\n",
      "0 9 962 G r\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "head data/Individual0_position962.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Outline](#outline)\n",
    "### Question 1\n",
    "##### Read in Q1 Data\n",
    "<a id=\"rq1d\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqRead:\n",
    "    def __init__(self,data):\n",
    "        rec = data.strip().split()\n",
    "        self.q = ord(rec[4]) - 33\n",
    "        self.errorProb = 10.0**((-self.q)/10.0)\n",
    "        self.call = rec[3]\n",
    "        self.matchesRef = False\n",
    "        \n",
    "pos962,pos964 = [],[]\n",
    "for line in open(\"data/Individual0_position962.txt\"): pos962.append(SeqRead(line))\n",
    "for line in open(\"data/Individual0_position964.txt\"): pos964.append(SeqRead(line))\n",
    "positions = [pos962,pos964]\n",
    "data, all_qs, all_errors, all_calls = [],[],[],[]\n",
    "for pos in positions:\n",
    "    calls, errorProbs, qscores = [],[],[]\n",
    "    for read in pos:\n",
    "        qscores.append(read.q)\n",
    "        errorProbs.append(read.errorProb)\n",
    "        calls.append(int(read.call=='A'))\n",
    "    all_calls.append(calls)   \n",
    "    all_qs.append(qscores) \n",
    "    all_errors.append(errorProbs)\n",
    "    qscores = Series(qscores)\n",
    "    data.append(qscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Describe and plot the distribution of Q scores to see data quality\n",
    "<a id=\"q1qc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual 0 Position 962 Quality score Distribution\n",
      " count    8883.000000\n",
      "mean       71.602837\n",
      "std        13.239879\n",
      "min         3.000000\n",
      "25%        71.000000\n",
      "50%        78.000000\n",
      "75%        80.000000\n",
      "max        81.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Individual 0 Position 962 Quality score Distribution\\n\",data[0].describe())\n",
    "data[0].hist().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual 0 Position 964 Quality score Distribution\n",
      " count    8886.000000\n",
      "mean       75.660027\n",
      "std         9.702624\n",
      "min         3.000000\n",
      "25%        77.000000\n",
      "50%        80.000000\n",
      "75%        80.000000\n",
      "max        81.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Individual 0 Position 964 Quality score Distribution\\n\",data[1].describe())\n",
    "data[1].hist().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Outline](#outline)\n",
    "<h5><a id='q1a'>Question 1a.</a></h5>\n",
    "\n",
    "![](images/Q1A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L(g|Z_1,Z_2,...,Z_l)$ def $\\stackrel{def}{=}$ $Pr(Z_1=z_1,Z_2=z_2,...,Z_l=z_l|G=g)$ \n",
    "\n",
    "$\\stackrel{CP}{=}$ $\\frac{Pr(Z_1=z_1 \\cap Z_2=z_2 \\cap...\\cap Z_l=z_l\\cap G=g)}{Pr(G=g)}$\n",
    "\n",
    "$\\stackrel{MR}{=}$ $\\frac{1}{Pr(G=g)} * Pr(Z_1=z_1) * Pr(Z_2=z_2|Z_1=z_1) * Pr(Z_3=z_3|Z_1=z_1 \\cap Z_2=z_2) * ... * Pr(Z_l=z_l | Z_1=z_1 \\cap ... \\cap Z_{l-1}=z_{l-1}) * Pr(G=g|Z_1=z_1 \\cap ... \\cap Z_l=z_l)$ \n",
    "\n",
    "Since G is independent of Z_n,\n",
    "\n",
    "$Pr(G = g | Z_1=z_1  \\cap ... \\cap  Z_l=z_l)$ = Pr(G = g)\n",
    "\n",
    "and Pr(G = g) cancels.\n",
    "\n",
    "$\\stackrel{Independance\\: of \\:reads}{=}$ $Pr(Z_1=z_1)Pr(Z_2=z_2)...Pr(Z_l=z_l)$\n",
    "\n",
    "$\\stackrel{WLOG}{=}$ ${\\displaystyle \\prod_{j=1}^{k} Pr(Z_j=1)}$ $\\cdot$ ${\\displaystyle \\prod_{j=k+1}^{l} Pr(Z_j=0)}$\n",
    "\n",
    "where $Z_j= \\mathbb{1}\\{D_j=b_r\\}$ is an indicator function matching the read $b_r$ to the reference allele $D_j$. A read either matches the reference $Z_j = 1$ or it doesn't $Z_j = 0$\n",
    "\n",
    "##### From the class lecture notes we know that Li makes the assumption that the probability of an error in observing a particular call in a read at a specific site is equal to $10^{-(ord(q)-33)/10}$ where q is the quality score of the read from the sequencer, which is recorded in the fastq file. So, the probability of an error $10^{-(ord(q)-33)/10}$ = $e_{ijs}$\n",
    "\n",
    "\n",
    "![](images/Tree.jpeg)\n",
    "\n",
    "Given that we are dealing with a diploid, we have to adjust the probability of an error for the read by the ploidy.\n",
    "\n",
    "Using the picture above we substituted the $Pr(Z_j = 0)$ and $Pr(Z_j = 1)$ with their respective tree combinations of the probility of having a success or failure to come up with the final equation mapping the probability of a genotype at a position given the reads at observed at that position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Outline](#outline)\n",
    "<h5>Question 1b.</h5>\n",
    "&nbsp; Use the data from three diploids at https://dorman.stat.iastate.edu/files/genotyping.txt to compute the likelihood of the data in individual 0 at sites 962 and 964 assuming the reference base in both cases is $n_{b}$ = A. What are your maximum likelihood estimates $\\hat{G}_{MLE,962}$ and $\\hat{G}_{MLE,964}$ of the genotypes? (These data are unforgivingly huge, so you may want to do selective reading of the data in some smart way.)</p>\n",
    "<br/>\n",
    "<h5><a id='q1bc'>Question 1b Code</a></h5>\n",
    "<h6> The code below (written by me) is taking the stored R functions in the file Q1_MLE.R (modified from the <a href=\"\">R code in the class notes</a>) and converting it to python functions which I then call. For your convenience I have displayed the function being used in R magic, though the R magic cell doesn't actually do anything.</H6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Q1_MLE.R', 'r') as fh: rtext = fh.read()\n",
    "rfuncts = STAP(rtext,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "log.likelihood.d.g <- function(genotype, calls, ploidy, errorProbs, coverage){\n",
    "  -coverage*log(ploidy) +\n",
    "  sum(\n",
    "      log(\n",
    "          ifelse(  calls == 1, \n",
    "                   genotype * (1 - errorProbs) + (ploidy - genotype) * errorProbs/3, \n",
    "                   (1 - errorProbs) * (ploidy - genotype) + genotype * errorProbs + (2*errorProbs*(ploidy-genotype))/3 \n",
    "                 )\n",
    "          )\n",
    "      )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding MLE:\n",
      "-6152.268491224305 1\n",
      "Finding MLE:\n",
      "-6160.344705015218 1\n"
     ]
    }
   ],
   "source": [
    "for pos in range(0,2):\n",
    "    print(\"Finding MLE:\")\n",
    "    calls = all_calls[pos]\n",
    "    errorProbs = all_errors[pos]\n",
    "    maxScore = None\n",
    "    G = None\n",
    "    for g in range(0,3):\n",
    "        L = rfuncts.log_likelihood_d_g(g,rArray(calls),2,rArray(errorProbs),len(calls))[0]\n",
    "        if not maxScore or maxScore < L: \n",
    "            maxScore=L\n",
    "            G=g\n",
    "    print (maxScore,G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Question 1b Answer</h5>\n",
    "The results above show that $\\hat{G}_{MLE,962}$ = 1, given that the max of the likelihood function is -6152.268. $\\hat{G}_{MLE,964}$ is also equal to 1 with the max of the likelihood function of -6160.3447."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Question 1c</h5>\n",
    "Now find the maximum a posterior estimates $\\hat{G}_{MAP,962}$ and $\\hat{G}_{MAP,964}$ and explain any additional assumptions you make.\n",
    "<h5><a id='q1cc'>Question 1c Code</a></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "log.likelihood.MAP <- function(g, a, m, e, k){\n",
    "  -k*log(m) + log(0.5) +\n",
    "    sum(\n",
    "        log(\n",
    "            ifelse(  a == 1, \n",
    "                     g * (1 - e) + (m - g) * e/3, \n",
    "                     (1 - e) * (m - g) + g * e + (2*e*(m-g))/3\n",
    "                  )\n",
    "        )\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatchesRefMLE(df,g,m,k):\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding MAP:\n",
      "-6152.961638404865 1\n",
      "Finding MAP:\n",
      "-6161.037852195778 1\n"
     ]
    }
   ],
   "source": [
    "for pos in range(0,2):\n",
    "    print(\"Finding MAP:\")\n",
    "    calls = all_calls[pos]\n",
    "    errorProbs = all_errors[pos]\n",
    "    maxScore = None\n",
    "    G = None\n",
    "    for g in range(0,3):\n",
    "        L = rfuncts.log_likelihood_MAP(g,rArray(calls),2,rArray(errorProbs),len(calls))[0]\n",
    "        if not maxScore or maxScore < L: \n",
    "            maxScore=L\n",
    "            G=g\n",
    "    print (maxScore,G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id='q1ca'>Question 1c Answers</a></h4>\n",
    "$\\hat{G}_{MAP,962}$ and $\\hat{G}_{MAP,964}$ are both one. We assumed a prior $P(G = g)$ of .5. We chose this value because our null hypothesis is that the individual these reads came from is homozygous reference. Having no knowledge of the reference allele, we chose .5 because the position is either a SNP or not a SNP, so one of 2 possibilities. We could have chose many other priors, but since $P(G = g)$ only scales the maximum likelihood, any value we put would give us the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id='q1d'>Question 1d</a></h4>\n",
    "\n",
    "##### What is your confidence in the MAP estimates? Provide a numeric measure of that confidence.\n",
    "\n",
    "Using the code below. we attempted to get a numerical estimate by using Asymptotic Confidence Intervals as described in the SNP calling notes from class. However, when we implemented the functions we (I) must have done something wrong with the derivations because for both we get a pval of 0, which is about what we would expect given that the data shows that there is a SNP there. From further searching I see that we were supposed to use the likelihood of \\psi but we ran out of time to make it work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-83316.69248101514\n",
      "-67592.65415952701\n",
      "1.2326293961526864\n",
      "lambda: -0.4182992163208919\n",
      "0.0\n",
      "\n",
      "\n",
      "-89699.69855779826\n",
      "-69222.3349671043\n",
      "1.2958201800101827\n",
      "lambda: -0.5182876766225387\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "Ls = rfuncts.log_likelihood_gmap(\"data/Pos962_data.txt\")\n",
    "L_Ho = float(Ls[2])\n",
    "print (L_Ho)\n",
    "L_Ha = min(float(Ls[0]),float(Ls[1]))\n",
    "print (L_Ha)\n",
    "Lambda = L_Ho/L_Ha\n",
    "print(Lambda)\n",
    "lambd = -2*log(Lambda)\n",
    "print(\"lambda:\",lambd)\n",
    "print(chi2.pdf(lambd,1))\n",
    "print(\"\\n\")\n",
    "\n",
    "Ls = rfuncts.log_likelihood_gmap(\"data/Pos964_data.txt\")\n",
    "L_Ho = float(Ls[2])\n",
    "print (L_Ho)\n",
    "L_Ha = min(float(Ls[0]),float(Ls[1]))\n",
    "print (L_Ha)\n",
    "\n",
    "Lambda = L_Ho/L_Ha\n",
    "print(Lambda)\n",
    "lambd = -2*log(Lambda)\n",
    "print(\"lambda:\",lambd)\n",
    "print (chi2.pdf(lambd,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49999968218679913\n",
      "0.49999968218679913\n"
     ]
    }
   ],
   "source": [
    "for fileName in [\"data/Pos962_data.txt\",\"data/Pos964_data.txt\"]:\n",
    "    psi = rfuncts.estimate_psi(fileName)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id='q1e'>Question 1e</a></h4>\n",
    "\n",
    "##### You should always look at your data and numeric summaries of it to make sure the data are consistent with assumptions your model is making. Do you see anything unusual in the data from these two sites? Are your conclusions and confidence affected?\n",
    "\n",
    "No, we already took a look at the data and 1 seems like a good estimate for the parameter G given that there appears to be a roughly equal number of A's and G's. Based on the quality score graphs I showed above we have really high quality reads so our answers wouldn't change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Question 2</h3>\n",
    "&nbsp; <p><b>a.</b>Produce a space-separated text file with the individual in set{0,1,2}, the site in set{764,765,...,1199}, and the p-value for rejecting H0. For computing the p-value, use Monte Carlo sampling to estimate</p>\n",
    "<h4><a id='q2cc'>Question 2 Code</a></h4>\n",
    "\n",
    "##### Python Helper classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter     \n",
    "class Locus:\n",
    "    def __init__(self,pos):\n",
    "        self.majorAllele = None\n",
    "        self.majorAlleleCount = -1\n",
    "        self.qscores = {0:[],1:[],2:[]}\n",
    "        self.errorProbs = {0:[],1:[],2:[]}\n",
    "        self.reads = {0:[],1:[],2:[]}\n",
    "        self.callMatchRef = {0:[],1:[],2:[]}\n",
    "        nuc_counter = {'A':0, 'C':0, 'G':0, 'T':0}\n",
    "        self.read_counter = {0:nuc_counter.copy(),    1:nuc_counter.copy(),    2:nuc_counter.copy()}\n",
    "        self.total_reads = {0:0,1:0,2:0}\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for key in self.qscores.keys():yield key\n",
    "            \n",
    "    def add(self,line,individual):\n",
    "        if line != \"\":\n",
    "            read = SeqRead(line)\n",
    "            self.reads[individual].append(read)\n",
    "            self.errorProbs[individual].append(read.errorProb)\n",
    "            self.read_counter[individual][read.call] += 1\n",
    "            self.total_reads[individual] += 1\n",
    "\n",
    "    def calcMajorAllele(self):\n",
    "        totals = {}\n",
    "        for base in ['A','C','G','T']:\n",
    "            for i in range(0,3):\n",
    "                try: totals[base] += self.read_counter[i][base]\n",
    "                except: totals[base] = self.read_counter[i][base]\n",
    "        totals = Counter(totals)\n",
    "        self.majorAllele, self.majorAlleleCount = totals.most_common(1)[0] \n",
    "        \n",
    "        for ind in self:\n",
    "            for read in self.reads[ind]:\n",
    "                self.callMatchRef[ind].append(int(read.call == self.majorAllele))\n",
    "#                 self.qscores[ind].append(read.q)\n",
    "        \n",
    "def ProcessPosition(pos):\n",
    "    curLocus = Locus(pos)\n",
    "    i_0_file = \"data/Individual0_position%i.txt\" % pos\n",
    "    i_1_file = \"data/Individual1_position%i.txt\" % pos\n",
    "    i_2_file = \"data/Individual2_position%i.txt\" % pos\n",
    "    for line in open(i_0_file): curLocus.add(line,0)\n",
    "    for line in open(i_1_file): curLocus.add(line,1)\n",
    "    for line in open(i_2_file): curLocus.add(line,2)\n",
    "    curLocus.calcMajorAllele()\n",
    "    return curLocus        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### R functions and R Coversion helper object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import STAP\n",
    "from rpy2.robjects.vectors import FloatVector as rArray\n",
    "with open('Q2_DPBinomial.R', 'r') as fh: rtext = fh.read()\n",
    "rfuncts = STAP(rtext,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from scipy.stats import bernoulli\n",
    "rbern=bernoulli.rvs \n",
    "import time\n",
    "nsims = 1000\n",
    "output = open(\"Question2.txt\",\"w\")\n",
    "output.write(\"Individual Pos MC-PVal PA-Pval NA-PVal BA-PVal MCBN-PVal\\n\")\n",
    "output.close()\n",
    "data=None\n",
    "failed, totalRuns = 0, 0\n",
    "for pos in range(764,764):\n",
    "    print( str(datetime.datetime.now()).split('.')[0])\n",
    "    print(pos)\n",
    "    data = ProcessPosition(pos)\n",
    "    for individual in data:\n",
    "        print(individual,pos,data.read_counter[individual],)\n",
    "        if data.total_reads[individual] == 0: #if there are no reads for that individual at that position\n",
    "            #output.write(\"%i %i %0.4f %0.4f %0.4f %0.4f %0.4f\\n\" % (individual,pos,0.0,0.0,0.0,0.0,0.0))\n",
    "            continue\n",
    "        successfulTrials = 0\n",
    "        refAllele = data.majorAllele\n",
    "        for sim in range(nsims):\n",
    "            numMatchesRef = 0\n",
    "            for read in data.reads[individual]:\n",
    "                #randomDraw = bern random (1-eij,1)\n",
    "                rdraw = rbern(1 - read.errorProb, size=1)[0]\n",
    "                numMatchesRef += rdraw\n",
    "            if numMatchesRef <= data.read_counter[individual][refAllele]: successfulTrials+=1\n",
    "            else: failed+=1\n",
    "            totalRuns+=1\n",
    "        MC_PVal   = successfulTrials/float(nsims)\n",
    "        PA_Pval   = rfuncts.dpbinom(data.read_counter[individual][refAllele],rArray(data.qscores[individual]),method=\"PA\")[0]\n",
    "        NA_PVal   = rfuncts.dpbinom(data.read_counter[individual][refAllele],rArray(data.qscores[individual]),method=\"NA\")[0]\n",
    "        BA_PVal   = rfuncts.dpbinom(data.read_counter[individual][refAllele],rArray(data.qscores[individual]),method=\"BA\")[0]\n",
    "        MCBN_PVal = rfuncts.dpbinom(data.read_counter[individual][refAllele],rArray(data.qscores[individual]),method=\"MC\")[0]\n",
    "        #outString = \"\\t\".join([str(individual),str(pos),\"%0.8f\" % MC_PVal,\"%0.8f\" % PA_Pval,\"%0.8f\" % NA_PVal,\"%0.8f\" % BA_PVal,\"%0.8f\" % MCBN_PVal,str(data.read_counter[individual],)])\n",
    "        #output.write(outString+\"\\n\")\n",
    "        output = open(\"Question2.txt\",\"a\")\n",
    "        output.write(\"%i %i %0.4f %0.4f %0.4f %0.4f %0.4f\\n\" % (individual,pos,MC_PVal,PA_Pval,NA_PVal,BA_PVal,MCBN_PVal))\n",
    "        output.close()\n",
    "output.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id='q2ab'>Question 2 A and B Answer Sample</a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Pos MC-PVal PA-Pval NA-PVal BA-PVal MCBN-PVal\n",
      "0 1000 0.0000 0.4502 0.0000 0.0000 0.0000\n",
      "1 1000 0.0000 0.4338 0.0000 0.0000 0.0000\n",
      "2 1000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "0 1001 0.0000 0.0004 0.0000 0.0000 0.0000\n",
      "1 1001 0.0000 0.0001 0.0000 0.0000 0.0000\n",
      "2 1001 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "0 1002 0.0000 0.3759 0.0000 0.0000 0.0000\n",
      "1 1002 0.0000 0.3815 0.0000 0.0000 0.0000\n",
      "2 1002 0.0000 0.4128 0.0000 0.0000 0.0000\n",
      "2 996 0.0000 0.4445 0.0000 0.0000 0.0000\n",
      "0 997 0.1820 0.4891 0.1371 0.2498 0.0725\n",
      "1 997 0.0000 0.4615 0.0001 0.0103 0.0001\n",
      "2 997 0.0000 0.4368 0.0000 0.0000 0.0000\n",
      "0 998 0.0000 0.4054 0.0000 0.0000 0.0000\n",
      "1 998 0.0000 0.4070 0.0000 0.0000 0.0000\n",
      "2 998 0.0000 0.3695 0.0000 0.0000 0.0000\n",
      "0 999 0.0000 0.4496 0.0000 0.0000 0.0000\n",
      "1 999 0.0000 0.4745 0.0000 0.0019 0.0000\n",
      "2 999 0.0000 0.3575 0.0000 0.0000 0.0000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head Question2_output.txt\n",
    "tail Question2_output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Outline](#outline)\n",
    "<h4><a id='q2c'>Question 2c</a></h4>\n",
    "For the most part I believe the results make sense. When we se a lot of reads that are all the same base we get 0 or close to 0. When there is a clear het, we get larger p values. The poison method appear to never have significant pvalues. The closest distribution to our monte carlo sampling mimicing a poisson binomail is the monte carlo simulation using a binomail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Outline](#outline)\n",
    "<h1><a id='q3'>Question 3</a></h1>\n",
    "<h4>Identify all the sites whose support for homozygosity is high</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of positions where all individuals are homozygous: 43\n"
     ]
    }
   ],
   "source": [
    "with open('Q1_MLE.R', 'r') as fh: rtext = fh.read()\n",
    "rfuncts = STAP(rtext,\"\")\n",
    "Gmaps = set()\n",
    "remove=set()\n",
    "#for each position in the data\n",
    "for pos in range(764,1200):\n",
    "    #1. Read the data for all 3 individuals at that position\n",
    "    data = ProcessPosition(pos)\n",
    "    #If there are no reads for an individual don't consider the position\n",
    "    if data.total_reads[0] == 0 or data.total_reads[1] == 0 or data.total_reads[2] == 0:\n",
    "        remove.add(pos)\n",
    "        continue\n",
    "\n",
    "    #2. For each individual\n",
    "    for ind in [0,1,2]:\n",
    "        #Determine G=2 Log likelihood\n",
    "        maxScore = rfuncts.log_likelihood_MAP(2,rArray(data.callMatchRef[ind]),2,rArray(data.errorProbs[ind]),data.total_reads[ind])[0]\n",
    "        \n",
    "        #Check to make sure G=1,0 are not bigger than G=2. If they are, remove position pos from being a homozygous position\n",
    "        gIs2 = True\n",
    "        for g in range(1,0,-1):\n",
    "            L = rfuncts.log_likelihood_MAP(g,rArray(data.callMatchRef[ind]),2,rArray(data.errorProbs[ind]),data.total_reads[ind])[0]\n",
    "            if maxScore < L: \n",
    "                gIs2 = False\n",
    "                remove.add(pos)\n",
    "                break\n",
    "        if gIs2: Gmaps.add(pos)\n",
    "\n",
    "homozygousPositions = Gmaps.difference(remove)\n",
    "pickle.dump(homozygousPositions,open(\"homoPos.p\",\"wb\"))\n",
    "print(\"Total number of positions where all individuals are homozygous:\",len(homozygousPositions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "homozygousPositions = pickle.load(open(\"homoPos.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id=\"q3g\">Group by TrueBase then by read call then by q</a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028 1031 1033 907 908 1042 915 1048 921 1055 1056 930 932 935 942 952 955 956 957 958 961 965 966 967 970 972 977 980 983 986 991 993 996 997 998 999 1002 1005 1006 1007 1008 1011 1021 "
     ]
    }
   ],
   "source": [
    "all_reads = {'A':{},'C':{},'G':{},'T':{}}  #{trueBase:{readCall:{q:count}}}\n",
    "all_qs = set()\n",
    "for pos in homozygousPositions:\n",
    "    print(pos,end=\" \")\n",
    "    data = ProcessPosition(pos)\n",
    "    ma = data.majorAllele\n",
    "    for ind in data:\n",
    "        for read in data.reads[ind]:\n",
    "#             if read.q == 2:\n",
    "#                 print(read.call,ma)\n",
    "            all_qs.add(read.q)\n",
    "            try: all_reads[ma][read.call][read.q] +=1\n",
    "            except: \n",
    "                try:all_reads[ma][read.call][read.q] = 1\n",
    "                except: all_reads[ma][read.call] = {read.q:1}\n",
    "pickle.dump(all_reads,open(\"aggregatedByMatchRefData.p\",\"wb\"))       \n",
    "pickle.dump(all_qs,open(\"all_qs.p\",\"wb\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reads = pickle.load(open(\"aggregatedByMatchRefData.p\",\"rb\"))\n",
    "all_qs = pickle.load(open(\"all_qs.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Question 3a</h2>\n",
    "<h4><a id=\"q3pq\">Estimate $\\hat{P_q}$ for all q</a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Q values: 80\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Q values:\",len(all_qs))\n",
    "\n",
    "bases = set(['A','C','G','T'])\n",
    "Phat_q = {}\n",
    "Q_matchingCounts = {}\n",
    "for q in all_qs:\n",
    "    totalReads = 0\n",
    "    notMatching = 0\n",
    "    for trueBase, calls in all_reads.items():\n",
    "        #Reads that match the ref base and Q=q\n",
    "        if q in all_reads[trueBase][trueBase]: totalReads += all_reads[trueBase][trueBase][q] \n",
    "            \n",
    "        #Reads that don't match the ref base and have Q=q\n",
    "        for readBase in bases.difference(set([trueBase])):\n",
    "            try: \n",
    "                notMatching += all_reads[trueBase][readBase][q]\n",
    "                totalReads  += all_reads[trueBase][readBase][q]\n",
    "            except:continue #Do nothing there are no reads with that base or that quality\n",
    "            #print (\"\\t\",q,refBase,base,all_reads[refBase][base][q])\n",
    "    \n",
    "    Q_matchingCounts[q] = [totalReads-notMatching,notMatching]  # {q:[#reads with Q=q and match ref, #reads with Q=q and do NOT match ref]}\n",
    "    phat_q = notMatching/float(totalReads)\n",
    "    #print (\"P_%i = %i / %i = %.8f\" % (q,notMatching,totalReads,phat_q))\n",
    "    Phat_q[q] = phat_q #Store p-hat_q %\n",
    "pickle.dump(Phat_q,open(\"Phat_q.p\",\"wb\")) \n",
    "pickle.dump(Q_matchingCounts,open(\"Q_matchingCounts.p\",\"wb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phat_q = pickle.load(open(\"Phat_q.p\",\"rb\")) \n",
    "Q_matchingCounts = pickle.load(open(\"Q_matchingCounts.p\",\"rb\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id=\"q3lho\">Plug all $\\hat{P}_{q}$ into the $L(H_o |  Data )$</a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.8446744073709564e+19\n"
     ]
    }
   ],
   "source": [
    "L_H_o = 0.0\n",
    "nparamsHo = 0\n",
    "for q in all_qs:\n",
    "    nparamsHo += 1\n",
    "    if Phat_q[q] == 0:\n",
    "        L_H_o -= MAXSIZE\n",
    "    else:\n",
    "        notError = Q_matchingCounts[q][0]*log(1-Phat_q[q])\n",
    "        error = Q_matchingCounts[q][1]*log(Phat_q[q])        \n",
    "        L_H_o +=  (notError + error)\n",
    "    #print(\"Q=%i (1-%.8f)^%i * (%.8f)^%i\" % (q,Phat_q[q],Q_matchingCounts[q][0],Phat_q[q],Q_matchingCounts[q][1]))\n",
    "print(L_H_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now Lets work on the $L(H_A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Ha.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id=\"q3pbq\">Estimate the $\\hat{P}_{bq}$ values</a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_QBs = {}\n",
    "P_QB_Counts = {}\n",
    "for trueBase in bases:\n",
    "    P_QBs[trueBase] = {}\n",
    "    P_QB_Counts[trueBase] = {}\n",
    "    for q in all_qs:\n",
    "        total_with_q = 0\n",
    "        dont_Match_True_Base = 0 \n",
    "        \n",
    "        if q in all_reads[trueBase][trueBase]:total_with_q = all_reads[trueBase][trueBase][q]\n",
    "        for readBase in bases.difference(set([trueBase])):\n",
    "            if q in all_reads[trueBase][readBase]:\n",
    "                dont_Match_True_Base += all_reads[trueBase][readBase][q]\n",
    "                total_with_q += all_reads[trueBase][readBase][q]\n",
    "        try:\n",
    "            P_QBs[trueBase][q] = dont_Match_True_Base / float(total_with_q)\n",
    "            P_QB_Counts[trueBase][q] = [total_with_q-dont_Match_True_Base,dont_Match_True_Base]\n",
    "        except: pass\n",
    "            #print (dont_Match_True_Base,total_with_q)\n",
    "pickle.dump(P_QB_Counts,open(\"P_QB_Counts.p\",\"wb\")) \n",
    "pickle.dump(P_QBs,open(\"P_QBs.p\",\"wb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_QB_Counts = pickle.load(open(\"P_QB_Counts.p\",\"rb\")) \n",
    "P_QBs = pickle.load(open(\"P_QBs.p\",\"rb\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id=\"q3lha\">Plug all $\\hat{P}_{qb}$ into $L(H_a |  Data )$</a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.611686018427388e+20\n"
     ]
    }
   ],
   "source": [
    "L_H_a = 0.0\n",
    "nparamsHa = 0\n",
    "for base in P_QBs:\n",
    "    for q in P_QBs[base]:\n",
    "        nparamsHa += 1\n",
    "        #print (\"P_%s%i = (%i * log(1-%.8f) + %i * log(%.8f))\" % (base, q, P_QB_Counts[base][q][0], P_QBs[base][q], P_QB_Counts[base][q][1], P_QBs[base][q]))\n",
    "        if P_QBs[base][q] == 0:\n",
    "            L_H_a -= MAXSIZE\n",
    "        else:\n",
    "            L_H_a += P_QB_Counts[base][q][0]*log(1-P_QBs[base][q]) + P_QB_Counts[base][q][1]*log(P_QBs[base][q])\n",
    "\n",
    "print(L_H_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id=\"q3pval\">Calculate the $P_{val}$ for the LRT</a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda 0.04000000000000003\n",
      "Lambda: 6.4377516497364\n",
      "P-Val: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"lambda\",L_H_o/L_H_a)\n",
    "print(\"Lambda:\",-2*log(L_H_o/L_H_a))\n",
    "print(\"P-Val:\",1-chi2.cdf(-2*log(L_H_o/L_H_a),nparamsHa-nparamsHo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"q3b\">Question 3b</a></h2>\n",
    "$\\hspace{10mm}$ \n",
    "$\\frac{L_0}{L_1} =$ \n",
    "$\\hspace{10mm}$ \n",
    "$\\frac{{\\displaystyle \\prod_{i=1}^{3}}{\\displaystyle \\prod_{j=1}^{l_i}}{\\displaystyle \\prod_{k=1}^{m_i}} (1-\\hat{p}_{q_{ijk}})^{\\mathbb{1}\\{R_{ijk}=b_{k}\\}}(\\hat{p}_{q_{ijk}})^{\\mathbb{1}\\{R_{k} \\neq b_{ijk}\\}}}{{\\displaystyle \\prod_{X=1}^{93}}{\\displaystyle \\prod_{i=1}^{3}}{\\displaystyle \\prod_{j=1}^{l_i}}{\\displaystyle \\prod_{k=1}^{m_i}}[(1-\\hat{p}_{b'_kq_{ijk}})^{\\mathbb{1}\\{R_{ijk}=b_k\\}}(\\hat{p}_{b'_kq_{ijk}})^{\\mathbb{1}\\{R_{ijk} \\neq b_k\\}}]^{{\\mathbb{1}\\{Q=X\\}}}}$\n",
    "\n",
    "<br></br>\n",
    "\n",
    "$\\prod_{i=1}^{q} (1-P_q)^{\\#match}*(P_q)^{\\# no match}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_QB_Primes = {}\n",
    "bases = set(['A','C','G','T'])\n",
    "P_QB_Prime_Counts = {}\n",
    "for trueBase in bases:\n",
    "    P_QB_Primes[trueBase] = {}\n",
    "    P_QB_Prime_Counts[trueBase] = {}\n",
    "    for q in all_qs:\n",
    "        total_with_q = 0\n",
    "        if q in all_reads[trueBase][trueBase]:total_with_q = all_reads[trueBase][trueBase][q]\n",
    "        mismatchCounter={}  \n",
    "        for readBase in bases.difference(set([trueBase])):\n",
    "            if q in all_reads[trueBase][readBase]:\n",
    "                mismatchCounter[readBase] = all_reads[trueBase][readBase][q]\n",
    "                total_with_q += all_reads[trueBase][readBase][q]\n",
    "            else: mismatchCounter[readBase] = 0.0\n",
    "        if total_with_q == 0: continue        \n",
    "        for base,mismatchCount in mismatchCounter.items():\n",
    "            try:\n",
    "                P_QB_Primes[trueBase][q][base] = mismatchCount / float(total_with_q)\n",
    "                P_QB_Prime_Counts[trueBase][q][base] = [total_with_q - mismatchCount, mismatchCount]\n",
    "            except:\n",
    "                P_QB_Primes[trueBase][q] = {base:mismatchCount / float(total_with_q)} \n",
    "                P_QB_Prime_Counts[trueBase][q] = {base:[total_with_q - mismatchCount, mismatchCount]}      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.8446744073709564e+19\n"
     ]
    }
   ],
   "source": [
    "L_H_o = 0.0\n",
    "nparamsHo = 0\n",
    "for q in all_qs:\n",
    "    nparamsHo += 1\n",
    "    if Phat_q[q] == 0: #pass\n",
    "        L_H_o -= MAXSIZE\n",
    "    else:\n",
    "        notError = Q_matchingCounts[q][0]*log(1-Phat_q[q])\n",
    "        error = Q_matchingCounts[q][1]*log(Phat_q[q])        \n",
    "        L_H_o +=  (notError + error)\n",
    "    #print(\"Q=%i (1-%.8f)^%i * (%.8f)^%i\" % (q,Phat_q[q],Q_matchingCounts[q][0],Phat_q[q],Q_matchingCounts[q][1]))\n",
    "print(L_H_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.1412940445477943e+21\n"
     ]
    }
   ],
   "source": [
    "L_H_a = 0.0\n",
    "nparamsHa = 0\n",
    "for trueBase in P_QB_Primes:\n",
    "    for q in P_QB_Primes[trueBase]:\n",
    "        for readBase, mmCount in P_QB_Primes[trueBase][q].items():\n",
    "            nparamsHa += 1\n",
    "            #print(\"Q=%i (1-%.8f)^%i * (%.8f)^%i\" % (q,P_QB_Primes[trueBase][q][readBase],P_QB_Prime_Counts[trueBase][q][readBase][0],P_QB_Primes[trueBase][q][readBase],P_QB_Prime_Counts[trueBase][q][readBase][1]))\n",
    "            if P_QB_Primes[trueBase][q][readBase] == 0.0: #pass\n",
    "                L_H_a -= MAXSIZE\n",
    "            else:\n",
    "                notError = P_QB_Prime_Counts[trueBase][q][readBase][0] * log(1-P_QB_Primes[trueBase][q][readBase])\n",
    "                error =    P_QB_Prime_Counts[trueBase][q][readBase][1] * log(P_QB_Primes[trueBase][q][readBase])\n",
    "                L_H_a +=  (notError + error)\n",
    "print(L_H_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda 0.004454342984409803\n",
      "Lambda: 10.827751414364617\n",
      "P-Val: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"lambda\",L_H_o/L_H_a)\n",
    "print(\"Lambda:\",-2*log(L_H_o/L_H_a))\n",
    "print(\"P-Val:\",1-chi2.cdf(-2*log(L_H_o/L_H_a),nparamsHo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><a id=\"q3c\">Question 3c</a></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qCount = {}\n",
    "for q in all_qs:\n",
    "    qDontMatch = 0\n",
    "    qMatches = 0\n",
    "    for trueBase in all_reads:\n",
    "        if q in all_reads[trueBase][trueBase]: qMatches += all_reads[trueBase][trueBase][q]\n",
    "        for readBase in bases.difference(set([trueBase])):\n",
    "            if q in all_reads[trueBase][readBase]:\n",
    "                qDontMatch += all_reads[trueBase][readBase][q]\n",
    "    qCount[q] = [qMatches, qDontMatch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda 2.751807645001757e-15\n",
      "Lambda: 67.05303674744155\n",
      "P-Val: 0.8487676211840466\n"
     ]
    }
   ],
   "source": [
    "L_H_o = 0.0\n",
    "L_H_a = 0.0\n",
    "for q in all_qs:\n",
    "    L_H_o += qCount[q][0] * log(1-10**(-q/10)) + qCount[q][1] * log((1/3)*(10**(-q/10)))\n",
    "    if Phat_q[q] == 0.0: L_H_a -= MAXSIZE\n",
    "    else: L_H_a += qCount[q][0] * log(1-Phat_q[q]) + qCount[q][1] * log(Phat_q[q])\n",
    "    \n",
    "print(\"lambda\",L_H_o/L_H_a)\n",
    "print(\"Lambda:\",-2*log(L_H_o/L_H_a))\n",
    "print(\"P-Val:\",1-chi2.cdf(-2*log(L_H_o/L_H_a),nparamsHo))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
