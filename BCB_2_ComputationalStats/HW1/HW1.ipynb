{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><a id='outline'>Project Outline</a></h1>\n",
    "\n",
    "* [Data Pre-Processing](#dpp)\n",
    "  *  [Required Libraries](#libs)\n",
    "  *  [Separate Data](#sep)\n",
    "  *  [General Data Overview](#gdo)\n",
    "* [Question 1](#rq1d)\n",
    "  *  [Read in Q1 Data](#rq1d)\n",
    "  *  [Quality Score Distribution](#sep)\n",
    "  *  [Separate Data](#sep)\n",
    "  *  [Question 1a](#q1a)\n",
    "  *  [Question 1b Code](#q1bc)\n",
    "  *  [Question 1b Answer](#q1ba)\n",
    "  *  [Question 1c Code](#q1cc)\n",
    "  *  [Question 1c Answer](#q1ca)\n",
    "  *  [Question 1d](#q1d)\n",
    "  *  [Question 1e](#q1e)\n",
    "* [Question 2](#q2cc)\n",
    "  * [Question 2 Code](#q2cc)\n",
    "  * [Question 2 Answer](#q2ab)\n",
    "  * [Question 2c](#q2c)\n",
    "* [Question 3](#q3)\n",
    "    * [Something is wrong here](#error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"dpp\">Data prep and cursory analysis</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id=\"libs\">Python Libraries and Jupyter Magic</a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "from pandas import Series\n",
    "from collections import Counter\n",
    "from rpy2.robjects.packages import STAP\n",
    "from rpy2.robjects.vectors import FloatVector as rArray\n",
    "from Locus import *\n",
    "from os import chdir\n",
    "import rpy2.rinterface\n",
    "import pickle\n",
    "chdir(\"/mnt/research/germs/shane/Classes/BCB_2_ComputationalStats/HW1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate Data\n",
    "<a id=\"sep\"></a>\n",
    "##### Divide the data by individual and position because github wont allow large files and this will allow us to only load small amounts of data into memory at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/\n",
    "for individual in {0..2}; do \n",
    "    for pos in {764..1199}; do\n",
    "        awk -v individual=\"$individual\" -v pos=\"$pos\" '($1==individual && $3==pos && $4!=\"NA\") {print $0}' genotyping.txt > Individual$individual\\_position$pos.txt\n",
    "    done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Data Overview \n",
    "<a id=\"gdo\"></a>\n",
    "<ol style=\"display: inline; padding: 0;margin-top: -10px;\"> <p style=\"display: inline; padding: 0;margin-top: -10px;\"><u>Genotyping.txt Column Designations:</u></p>\n",
    "    <li>Id of individual</li>\n",
    "    <li>Id of read</li>\n",
    "    <li>Reference position</li>\n",
    "    <li>Read base call</li>\n",
    "    <li>Read quality score</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 962 A p\n",
      "0 1 962 A h\n",
      "0 2 962 A i\n",
      "0 3 962 A l\n",
      "0 4 962 G X\n",
      "0 5 962 G p\n",
      "0 6 962 G p\n",
      "0 7 962 A p\n",
      "0 8 962 A p\n",
      "0 9 962 G r\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "head data/Individual0_position962.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Outline](#outline)\n",
    "### Question 1\n",
    "##### Read in Q1 Data\n",
    "<a id=\"rq1d\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqRead:\n",
    "    def __init__(self,data):\n",
    "        rec = data.strip().split()\n",
    "        self.q = ord(rec[4]) - 33\n",
    "        self.errorProb = 10.0**((-self.q)/10.0)\n",
    "        self.call = rec[3]\n",
    "        self.matchesRef = False\n",
    "        \n",
    "pos962,pos964 = [],[]\n",
    "for line in open(\"data/Individual0_position962.txt\"): pos962.append(SeqRead(line))\n",
    "for line in open(\"data/Individual0_position964.txt\"): pos964.append(SeqRead(line))\n",
    "positions = [pos962,pos964]\n",
    "data, all_qs, all_errors, all_calls = [],[],[],[]\n",
    "for pos in positions:\n",
    "    calls, errorProbs, qscores = [],[],[]\n",
    "    for read in pos:\n",
    "        qscores.append(read.q)\n",
    "        errorProbs.append(read.errorProb)\n",
    "        calls.append(int(read.call=='A'))\n",
    "    all_calls.append(calls)   \n",
    "    all_qs.append(qscores) \n",
    "    all_errors.append(errorProbs)\n",
    "    qscores = Series(qscores)\n",
    "    data.append(qscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Describe and plot the distribution of Q scores to see data quality\n",
    "<a id=\"q1qc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual 0 Position 962 Quality score Distribution\n",
      " count    8883.000000\n",
      "mean       71.602837\n",
      "std        13.239879\n",
      "min         3.000000\n",
      "25%        71.000000\n",
      "50%        78.000000\n",
      "75%        80.000000\n",
      "max        81.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Individual 0 Position 962 Quality score Distribution\\n\",data[0].describe())\n",
    "data[0].hist().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual 0 Position 964 Quality score Distribution\n",
      " count    8886.000000\n",
      "mean       75.660027\n",
      "std         9.702624\n",
      "min         3.000000\n",
      "25%        77.000000\n",
      "50%        80.000000\n",
      "75%        80.000000\n",
      "max        81.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Individual 0 Position 964 Quality score Distribution\\n\",data[1].describe())\n",
    "data[1].hist().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Outline](#outline)\n",
    "<h5><a id='q1a'>Question 1a.</a></h5>\n",
    "\n",
    "![](images/Q1A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L(g|Z_1,Z_2,...,Z_l)$ def $\\stackrel{def}{=}$ $Pr(Z_1=z_1,Z_2=z_2,...,Z_l=z_l|G=g)$ \n",
    "\n",
    "$\\stackrel{CP}{=}$ $\\frac{Pr(Z_1=z_1 \\cap Z_2=z_2 \\cap...\\cap Z_l=z_l\\cap G=g)}{Pr(G=g)}$\n",
    "\n",
    "$\\stackrel{MR}{=}$ $\\frac{1}{Pr(G=g)} * Pr(Z_1=z_1) * Pr(Z_2=z_2|Z_1=z_1) * Pr(Z_3=z_3|Z_1=z_1 \\cap Z_2=z_2) * ... * Pr(Z_l=z_l | Z_1=z_1 \\cap ... \\cap Z_{l-1}=z_{l-1}) * Pr(G=g|Z_1=z_1 \\cap ... \\cap Z_l=z_l)$ \n",
    "\n",
    "Since G is independent of Z_n,\n",
    "\n",
    "$Pr(G = g | Z_1=z_1  \\cap ... \\cap  Z_l=z_l)$ = Pr(G = g)\n",
    "\n",
    "and Pr(G = g) cancels.\n",
    "\n",
    "$\\stackrel{Independance\\: of \\:reads}{=}$ $Pr(Z_1=z_1)Pr(Z_2=z_2)...Pr(Z_l=z_l)$\n",
    "\n",
    "$\\stackrel{WLOG}{=}$ ${\\displaystyle \\prod_{j=1}^{k} Pr(Z_j=1)}$ $\\cdot$ ${\\displaystyle \\prod_{j=k+1}^{l} Pr(Z_j=0)}$\n",
    "\n",
    "where $Z_j= \\mathbb{1}\\{D_j=b_r\\}$ is an indicator function matching the read $b_r$ to the reference allele $D_j$. A read either matches the reference $Z_j = 1$ or it doesn't $Z_j = 0$\n",
    "\n",
    "##### From the class lecture notes we know that Li makes the assumption that the probability of an error in observing a particular call in a read at a specific site is equal to $10^{-(ord(q)-33)/10}$ where q is the quality score of the read from the sequencer, which is recorded in the fastq file. So, the probability of an error $10^{-(ord(q)-33)/10}$ = $e_{ijs}$\n",
    "\n",
    "\n",
    "![](images/Tree.jpeg)\n",
    "\n",
    "Given that we are dealing with a diploid, we have to adjust the probability of an error for the read by the ploidy.\n",
    "\n",
    "Using the picture above we substituted the $Pr(Z_j = 0)$ and $Pr(Z_j = 1)$ with their respective tree combinations of the probility of having a success or failure to come up with the final equation mapping the probability of a genotype at a position given the reads at observed at that position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/research/germs/shane/Classes/BCB_2_ComputationalStats/HW1\n",
      "Q1A.png\n",
      "Tree.jpeg\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd\n",
    "ls images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Outline](#outline)\n",
    "<h5>Question 1b.</h5>\n",
    "&nbsp; Use the data from three diploids at https://dorman.stat.iastate.edu/files/genotyping.txt to compute the likelihood of the data in individual 0 at sites 962 and 964 assuming the reference base in both cases is $n_{b}$ = A. What are your maximum likelihood estimates $\\hat{G}_{MLE,962}$ and $\\hat{G}_{MLE,964}$ of the genotypes? (These data are unforgivingly huge, so you may want to do selective reading of the data in some smart way.)</p>\n",
    "<br/>\n",
    "<h5><a id='q1bc'>Question 1b Code</a></h5>\n",
    "\n",
    "###### The code below (written by me) is taking the stored R functions in the file Q1_MLE.R (modified from the R code in the class notes) and converting it to python functions which I then call. For your convenience I have displayed the function being used in R magic, though the R magic cell doesn't actually do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Q1_MLE.R', 'r') as fh: rtext = fh.read()\n",
    "rfuncts = STAP(rtext,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "log.likelihood.d.g <- function(genotype, calls, ploidy, errorProbs, coverage){\n",
    "  -coverage*log(ploidy) +\n",
    "  sum(\n",
    "      log(\n",
    "          ifelse(  calls == 1, \n",
    "                   genotype * (1 - errorProbs) + (ploidy - genotype) * errorProbs/3, \n",
    "                   (1 - errorProbs) * (ploidy - genotype) + genotype * errorProbs + (2*errorProbs*(ploidy-genotype))/3 \n",
    "                 )\n",
    "          )\n",
    "      )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding MLE:\n",
      "-6152.268491224305 1\n",
      "Finding MLE:\n",
      "-6160.344705015218 1\n"
     ]
    }
   ],
   "source": [
    "for pos in range(0,2):\n",
    "    print(\"Finding MLE:\")\n",
    "    calls = all_calls[pos]\n",
    "    errorProbs = all_errors[pos]\n",
    "    maxScore = None\n",
    "    G = None\n",
    "    for g in range(0,3):\n",
    "        L = rfuncts.log_likelihood_d_g(g,rArray(calls),2,rArray(errorProbs),len(calls))[0]\n",
    "        if not maxScore or maxScore < L: \n",
    "            maxScore=L\n",
    "            G=g\n",
    "    print (maxScore,G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Question 1b Answer</h5>\n",
    "The results above show that $\\hat{G}_{MLE,962}$ = 1, given that the max of the likelihood function is -6152.268. $\\hat{G}_{MLE,964}$ is also equal to 1 with the max of the likelihood function of -6160.3447."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Question 1c</h5>\n",
    "Now find the maximum a posterior estimates $\\hat{G}_{MAP,962}$ and $\\hat{G}_{MAP,964}$ and explain any additional assumptions you make.\n",
    "<h5><a id='q1cc'>Question 1c Code</a></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "log.likelihood.MAP <- function(g, a, m, e, k){\n",
    "  -k*log(m) + log(0.5) +\n",
    "    sum(\n",
    "        log(\n",
    "            ifelse(  a == 1, \n",
    "                     g * (1 - e) + (m - g) * e/3, \n",
    "                     (1 - e) * (m - g) + g * e + (2*e*(m-g))/3\n",
    "                  )\n",
    "        )\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatchesRefMLE(df,g,m,k):\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding MAP:\n",
      "-6152.961638404865 1\n",
      "Finding MAP:\n",
      "-6161.037852195778 1\n"
     ]
    }
   ],
   "source": [
    "for pos in range(0,2):\n",
    "    print(\"Finding MAP:\")\n",
    "    calls = all_calls[pos]\n",
    "    errorProbs = all_errors[pos]\n",
    "    maxScore = None\n",
    "    G = None\n",
    "    for g in range(0,3):\n",
    "        L = rfuncts.log_likelihood_MAP(g,rArray(calls),2,rArray(errorProbs),len(calls))[0]\n",
    "        if not maxScore or maxScore < L: \n",
    "            maxScore=L\n",
    "            G=g\n",
    "    print (maxScore,G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id='q1ca'>Question 1c Answers</a></h4>\n",
    "$\\hat{G}_{MAP,962}$ and $\\hat{G}_{MAP,964}$ are both one. We assumed a prior $P(G = g)$ of .5. We chose this value because our null hypothesis is that the individual these reads came from is homozygous reference. Having no knowledge of the reference allele, we chose .5 because the position is either a SNP or not a SNP, so one of 2 possibilities. We could have chose many other priors, but since $P(G = g)$ only scales the maximum likelihood, any value we put would give us the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id='q1d'>Question 1d</a></h4>\n",
    "\n",
    "##### What is your confidence in the MAP estimates? Provide a numeric measure of that confidence.\n",
    "\n",
    "Using the code below. we attempted to get a numerical estimate by using Asymptotic Confidence Intervals as described in the SNP calling notes from class. However, when we implemented the functions we (I) must have done something wrong with the derivations because for both we get a pval of 0, which is about what we would expect given that the data shows that there is a SNP there. From further searching I see that we were supposed to use the likelihood of \\psi but we ran out of time to make it work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-83316.69248101514\n",
      "-67592.65415952701\n",
      "1.2326293961526864\n",
      "lambda: -0.4182992163208919\n",
      "0.0\n",
      "\n",
      "\n",
      "-89699.69855779826\n",
      "-69222.3349671043\n",
      "1.2958201800101827\n",
      "lambda: -0.5182876766225387\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "Ls = rfuncts.log_likelihood_gmap(\"data/Pos962_data.txt\")\n",
    "L_Ho = float(Ls[2])\n",
    "print (L_Ho)\n",
    "L_Ha = min(float(Ls[0]),float(Ls[1]))\n",
    "print (L_Ha)\n",
    "Lambda = L_Ho/L_Ha\n",
    "print(Lambda)\n",
    "lambd = -2*log(Lambda)\n",
    "print(\"lambda:\",lambd)\n",
    "print(chi2.pdf(lambd,1))\n",
    "print(\"\\n\")\n",
    "\n",
    "Ls = rfuncts.log_likelihood_gmap(\"data/Pos964_data.txt\")\n",
    "L_Ho = float(Ls[2])\n",
    "print (L_Ho)\n",
    "L_Ha = min(float(Ls[0]),float(Ls[1]))\n",
    "print (L_Ha)\n",
    "\n",
    "Lambda = L_Ho/L_Ha\n",
    "print(Lambda)\n",
    "lambd = -2*log(Lambda)\n",
    "print(\"lambda:\",lambd)\n",
    "print (chi2.pdf(lambd,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49999968218679913\n",
      "0.49999968218679913\n"
     ]
    }
   ],
   "source": [
    "for fileName in [\"data/Pos962_data.txt\",\"data/Pos964_data.txt\"]:\n",
    "    psi = rfuncts.estimate_psi(fileName)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id='q1e'>Question 1e</a></h4>\n",
    "\n",
    "##### You should always look at your data and numeric summaries of it to make sure the data are consistent with assumptions your model is making. Do you see anything unusual in the data from these two sites? Are your conclusions and confidence affected?\n",
    "\n",
    "No, we already took a look at the data and 1 seems like a good estimate for the parameter G given that there appears to be a roughly equal number of A's and G's. Based on the quality score graphs I showed above we have really high quality reads so our answers wouldn't change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Question 2</h3>\n",
    "&nbsp; <p><b>a.</b>Produce a space-separated text file with the individual in set{0,1,2}, the site in set{764,765,...,1199}, and the p-value for rejecting H0. For computing the p-value, use Monte Carlo sampling to estimate</p>\n",
    "<h4><a id='q2cc'>Question 2 Code</a></h4>\n",
    "\n",
    "##### Python Helper classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter     \n",
    "class Locus:\n",
    "    def __init__(self,pos):\n",
    "        self.majorAllele = None\n",
    "        self.majorAlleleCount = -1\n",
    "        self.qscores = {0:[],1:[],2:[]}\n",
    "        self.errorProbs = {0:[],1:[],2:[]}\n",
    "        self.reads = {0:[],1:[],2:[]}\n",
    "        self.callMatchRef = {0:[],1:[],2:[]}\n",
    "        nuc_counter = {'A':0, 'C':0, 'G':0, 'T':0}\n",
    "        self.read_counter = {0:nuc_counter.copy(),    1:nuc_counter.copy(),    2:nuc_counter.copy()}\n",
    "        self.total_reads = {0:0,1:0,2:0}\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for key in self.qscores.keys():yield key\n",
    "            \n",
    "    def add(self,line,individual):\n",
    "        if line != \"\":\n",
    "            read = SeqRead(line)\n",
    "            self.reads[individual].append(read)\n",
    "            self.errorProbs[individual].append(read.errorProb)\n",
    "            self.read_counter[individual][read.call] += 1\n",
    "            self.total_reads[individual] += 1\n",
    "\n",
    "    def calcMajorAllele(self):\n",
    "        totals = {}\n",
    "        for base in ['A','C','G','T']:\n",
    "            for i in range(0,3):\n",
    "                try: totals[base] += self.read_counter[i][base]\n",
    "                except: totals[base] = self.read_counter[i][base]\n",
    "        totals = Counter(totals)\n",
    "        self.majorAllele, self.majorAlleleCount = totals.most_common(1)[0] \n",
    "        \n",
    "        for ind in self:\n",
    "            for read in self.reads[ind]:\n",
    "                self.callMatchRef[ind].append(int(read.call == self.majorAllele))\n",
    "#                 self.qscores[ind].append(read.q)\n",
    "        \n",
    "def ProcessPosition(pos):\n",
    "    curLocus = Locus(pos)\n",
    "    i_0_file = \"data/Individual0_position%i.txt\" % pos\n",
    "    i_1_file = \"data/Individual1_position%i.txt\" % pos\n",
    "    i_2_file = \"data/Individual2_position%i.txt\" % pos\n",
    "    for line in open(i_0_file): curLocus.add(line,0)\n",
    "    for line in open(i_1_file): curLocus.add(line,1)\n",
    "    for line in open(i_2_file): curLocus.add(line,2)\n",
    "    curLocus.calcMajorAllele()\n",
    "    return curLocus        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### R functions and R Coversion helper object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import STAP\n",
    "from rpy2.robjects.vectors import FloatVector as rArray\n",
    "with open('Q2_DPBinomial.R', 'r') as fh: rtext = fh.read()\n",
    "rfuncts = STAP(rtext,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from scipy.stats import bernoulli\n",
    "rbern=bernoulli.rvs \n",
    "import time\n",
    "nsims = 1000\n",
    "output = open(\"Question2.txt\",\"w\")\n",
    "output.write(\"Individual Pos MC-PVal PA-Pval NA-PVal BA-PVal MCBN-PVal\\n\")\n",
    "output.close()\n",
    "data=None\n",
    "failed, totalRuns = 0, 0\n",
    "for pos in range(764,764):\n",
    "    print( str(datetime.datetime.now()).split('.')[0])\n",
    "    print(pos)\n",
    "    data = ProcessPosition(pos)\n",
    "    for individual in data:\n",
    "        print(individual,pos,data.read_counter[individual],)\n",
    "        if data.total_reads[individual] == 0: #if there are no reads for that individual at that position\n",
    "            #output.write(\"%i %i %0.4f %0.4f %0.4f %0.4f %0.4f\\n\" % (individual,pos,0.0,0.0,0.0,0.0,0.0))\n",
    "            continue\n",
    "        successfulTrials = 0\n",
    "        refAllele = data.majorAllele\n",
    "        for sim in range(nsims):\n",
    "            numMatchesRef = 0\n",
    "            for read in data.reads[individual]:\n",
    "                #randomDraw = bern random (1-eij,1)\n",
    "                rdraw = rbern(1 - read.errorProb, size=1)[0]\n",
    "                numMatchesRef += rdraw\n",
    "            if numMatchesRef <= data.read_counter[individual][refAllele]: successfulTrials+=1\n",
    "            else: failed+=1\n",
    "            totalRuns+=1\n",
    "        MC_PVal   = successfulTrials/float(nsims)\n",
    "        PA_Pval   = rfuncts.dpbinom(data.read_counter[individual][refAllele],rArray(data.qscores[individual]),method=\"PA\")[0]\n",
    "        NA_PVal   = rfuncts.dpbinom(data.read_counter[individual][refAllele],rArray(data.qscores[individual]),method=\"NA\")[0]\n",
    "        BA_PVal   = rfuncts.dpbinom(data.read_counter[individual][refAllele],rArray(data.qscores[individual]),method=\"BA\")[0]\n",
    "        MCBN_PVal = rfuncts.dpbinom(data.read_counter[individual][refAllele],rArray(data.qscores[individual]),method=\"MC\")[0]\n",
    "        #outString = \"\\t\".join([str(individual),str(pos),\"%0.8f\" % MC_PVal,\"%0.8f\" % PA_Pval,\"%0.8f\" % NA_PVal,\"%0.8f\" % BA_PVal,\"%0.8f\" % MCBN_PVal,str(data.read_counter[individual],)])\n",
    "        #output.write(outString+\"\\n\")\n",
    "        output = open(\"Question2.txt\",\"a\")\n",
    "        output.write(\"%i %i %0.4f %0.4f %0.4f %0.4f %0.4f\\n\" % (individual,pos,MC_PVal,PA_Pval,NA_PVal,BA_PVal,MCBN_PVal))\n",
    "        output.close()\n",
    "output.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><a id='q2ab'>Question 2 A and B Answer Sample</a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Pos MC-PVal PA-Pval NA-PVal BA-PVal MCBN-PVal\n",
      "0 1000 0.0000 0.4502 0.0000 0.0000 0.0000\n",
      "1 1000 0.0000 0.4338 0.0000 0.0000 0.0000\n",
      "2 1000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "0 1001 0.0000 0.0004 0.0000 0.0000 0.0000\n",
      "1 1001 0.0000 0.0001 0.0000 0.0000 0.0000\n",
      "2 1001 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "0 1002 0.0000 0.3759 0.0000 0.0000 0.0000\n",
      "1 1002 0.0000 0.3815 0.0000 0.0000 0.0000\n",
      "2 1002 0.0000 0.4128 0.0000 0.0000 0.0000\n",
      "2 996 0.0000 0.4445 0.0000 0.0000 0.0000\n",
      "0 997 0.1820 0.4891 0.1371 0.2498 0.0725\n",
      "1 997 0.0000 0.4615 0.0001 0.0103 0.0001\n",
      "2 997 0.0000 0.4368 0.0000 0.0000 0.0000\n",
      "0 998 0.0000 0.4054 0.0000 0.0000 0.0000\n",
      "1 998 0.0000 0.4070 0.0000 0.0000 0.0000\n",
      "2 998 0.0000 0.3695 0.0000 0.0000 0.0000\n",
      "0 999 0.0000 0.4496 0.0000 0.0000 0.0000\n",
      "1 999 0.0000 0.4745 0.0000 0.0019 0.0000\n",
      "2 999 0.0000 0.3575 0.0000 0.0000 0.0000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head Question2_output.txt\n",
    "tail Question2_output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Outline](#outline)\n",
    "<h4><a id='q2c'>Question 2c</a></h4>\n",
    "For the most part I believe the results make sense. When we se a lot of reads that are all the same base we get 0 or close to 0. When there is a clear het, we get larger p values. The poison method appear to never have significant pvalues. The closest distribution to our monte carlo sampling mimicing a poisson binomail is the monte carlo simulation using a binomail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project Outline](#outline)\n",
    "<h1><a id='q3'>Question 3</a></h1>\n",
    "<h4>Identify all the sites whose support for homozygosity is high</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of positions where all individuals are homozygous: 310\n"
     ]
    }
   ],
   "source": [
    "with open('Q1_MLE.R', 'r') as fh: rtext = fh.read()\n",
    "rfuncts = STAP(rtext,\"\")\n",
    "Gmaps = set()\n",
    "remove=set()\n",
    "#for each position in the data\n",
    "for pos in range(764,1200):\n",
    "    #1. Read the data for all 3 individuals at that position\n",
    "    data = ProcessPosition(pos)\n",
    "    \n",
    "    #2. For each individual\n",
    "    for ind in [0,1,2]:\n",
    "        #If there are no reads for that individual move to the next individual\n",
    "        if data.total_reads[ind] == 0 : continue\n",
    "            \n",
    "        #Determine G=2 Log likelihood\n",
    "        maxScore = rfuncts.log_likelihood_MAP(2,rArray(data.callMatchRef[ind]),2,rArray(data.errorProbs[ind]),data.total_reads[ind])[0]\n",
    "        \n",
    "        #Check to make sure G=1,0 are not bigger than G=2. If they are, remove position pos from being a homozygous position\n",
    "        gIs2 = True\n",
    "        for g in range(1,0,-1):\n",
    "            L = rfuncts.log_likelihood_MAP(g,rArray(data.callMatchRef[ind]),2,rArray(data.errorProbs[ind]),data.total_reads[ind])[0]\n",
    "            if maxScore < L: \n",
    "                gIs2 = False\n",
    "                remove.add(pos)\n",
    "                break\n",
    "        if gIs2: Gmaps.add(pos)\n",
    "\n",
    "homozygousPositions = Gmaps.difference(remove)\n",
    "pickle.dump(homozygousPositions,open(\"homoPos.p\",\"wb\"))\n",
    "\n",
    "print(\"Total number of positions where all individuals are homozygous:\",len(homozygousPositions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "homozygousPositions = pickle.load(open(\"homoPos.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Group by TrueBase then by read call then by q</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 840 841 842 843 844 845 846 847 848 849 850 851 852 853 855 856 857 858 859 860 861 862 863 864 865 867 868 869 870 871 872 873 874 875 876 877 879 880 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 903 907 908 915 921 930 932 935 942 952 955 956 957 958 961 965 966 967 970 972 977 980 983 986 991 993 996 997 998 999 1002 1005 1006 1007 1008 1011 1021 1028 1031 1033 1042 1048 1055 1056 1060 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1083 1084 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 "
     ]
    }
   ],
   "source": [
    "all_reads = {'A':{},'C':{},'G':{},'T':{}}  #{trueBase:{readCall:{q:count}}}\n",
    "all_qs = set()\n",
    "for pos in homozygousPositions:\n",
    "    print(pos,end=\" \")\n",
    "    data = ProcessPosition(pos)\n",
    "    ma = data.majorAllele\n",
    "    for ind in data:\n",
    "        for read in data.reads[ind]:\n",
    "#             if read.q == 2:\n",
    "#                 print(read.call,ma)\n",
    "            all_qs.add(read.q)\n",
    "            try: all_reads[ma][read.call][read.q] +=1\n",
    "            except: \n",
    "                try:all_reads[ma][read.call][read.q] = 1\n",
    "                except: all_reads[ma][read.call] = {read.q:1}\n",
    "pickle.dump(all_reads,open(\"aggregatedByMatchRefData.p\",\"wb\"))       \n",
    "pickle.dump(all_qs,open(\"all_qs.p\",\"wb\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reads = pickle.load(open(\"aggregatedByMatchRefData.p\",\"rb\"))\n",
    "all_qs = pickle.load(open(\"all_qs.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Q values: 81\n",
      "P_2 = 621 / 1376 = 0.45130814\n",
      "P_3 = 790 / 1923 = 0.41081643\n",
      "P_4 = 921 / 3780 = 0.24365079\n",
      "P_5 = 326 / 1515 = 0.21518152\n",
      "P_6 = 258 / 1372 = 0.18804665\n",
      "P_7 = 47 / 328 = 0.14329268\n",
      "P_8 = 126 / 734 = 0.17166213\n",
      "P_9 = 66 / 493 = 0.13387424\n",
      "P_10 = 133 / 726 = 0.18319559\n",
      "P_11 = 37 / 650 = 0.05692308\n",
      "P_12 = 33 / 1117 = 0.02954342\n",
      "P_13 = 23 / 1345 = 0.01710037\n",
      "P_14 = 126 / 3601 = 0.03499028\n",
      "P_15 = 288 / 12224 = 0.02356021\n",
      "P_16 = 1076 / 24969 = 0.04309344\n",
      "P_17 = 250 / 14420 = 0.01733703\n",
      "P_18 = 200 / 6574 = 0.03042288\n",
      "P_19 = 236 / 7781 = 0.03033029\n",
      "P_20 = 122 / 6515 = 0.01872602\n",
      "P_21 = 15 / 3186 = 0.00470810\n",
      "P_22 = 15 / 5302 = 0.00282912\n",
      "P_23 = 18 / 6454 = 0.00278897\n",
      "P_24 = 30 / 16109 = 0.00186231\n",
      "P_25 = 32 / 11603 = 0.00275791\n",
      "P_26 = 19 / 16977 = 0.00111916\n",
      "P_27 = 14 / 14756 = 0.00094877\n",
      "P_28 = 1 / 10 = 0.10000000\n",
      "P_29 = 42 / 6403 = 0.00655943\n",
      "P_30 = 66 / 17638 = 0.00374192\n",
      "P_31 = 52 / 12756 = 0.00407651\n",
      "P_32 = 277 / 93794 = 0.00295328\n",
      "P_33 = 212 / 114444 = 0.00185243\n",
      "P_34 = 178 / 97591 = 0.00182394\n",
      "P_35 = 78 / 30391 = 0.00256655\n",
      "P_36 = 161 / 52135 = 0.00308814\n",
      "P_37 = 309 / 315831 = 0.00097837\n",
      "P_38 = 1080 / 549827 = 0.00196425\n",
      "P_39 = 564 / 300124 = 0.00187922\n",
      "P_40 = 0 / 4 = 0.00000000\n",
      "P_41 = 0 / 15 = 0.00000000\n",
      "P_42 = 12 / 4343 = 0.00276307\n",
      "P_43 = 14 / 4039 = 0.00346620\n",
      "P_44 = 27 / 8307 = 0.00325027\n",
      "P_45 = 18 / 7720 = 0.00233161\n",
      "P_46 = 29 / 10424 = 0.00278204\n",
      "P_47 = 23 / 8446 = 0.00272318\n",
      "P_48 = 37 / 12420 = 0.00297907\n",
      "P_49 = 26 / 14952 = 0.00173890\n",
      "P_50 = 46 / 18037 = 0.00255031\n",
      "P_51 = 53 / 19884 = 0.00266546\n",
      "P_52 = 81 / 36316 = 0.00223042\n",
      "P_53 = 96 / 51272 = 0.00187237\n",
      "P_54 = 190 / 99873 = 0.00190242\n",
      "P_55 = 300 / 183721 = 0.00163291\n",
      "P_56 = 256 / 171782 = 0.00149026\n",
      "P_57 = 202 / 123576 = 0.00163462\n",
      "P_58 = 130 / 92639 = 0.00140330\n",
      "P_59 = 29 / 12807 = 0.00226439\n",
      "P_60 = 29 / 8132 = 0.00356616\n",
      "P_61 = 24 / 8655 = 0.00277296\n",
      "P_62 = 19 / 8599 = 0.00220956\n",
      "P_63 = 12 / 9884 = 0.00121408\n",
      "P_64 = 50 / 22191 = 0.00225317\n",
      "P_65 = 68 / 30000 = 0.00226667\n",
      "P_66 = 153 / 85469 = 0.00179012\n",
      "P_67 = 173 / 111181 = 0.00155602\n",
      "P_68 = 137 / 92854 = 0.00147543\n",
      "P_69 = 143 / 97423 = 0.00146783\n",
      "P_70 = 62 / 38319 = 0.00161800\n",
      "P_71 = 103 / 41929 = 0.00245653\n",
      "P_72 = 125 / 57381 = 0.00217842\n",
      "P_73 = 179 / 80279 = 0.00222972\n",
      "P_74 = 231 / 120798 = 0.00191228\n",
      "P_75 = 336 / 187170 = 0.00179516\n",
      "P_76 = 370 / 175265 = 0.00211109\n",
      "P_77 = 300 / 192115 = 0.00156156\n",
      "P_78 = 348 / 173039 = 0.00201111\n",
      "P_79 = 734 / 390186 = 0.00188115\n",
      "P_80 = 936 / 499984 = 0.00187206\n",
      "P_81 = 451 / 294409 = 0.00153188\n",
      "P_82 = 198 / 130173 = 0.00152105\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Q values:\",len(all_qs))\n",
    "Phat_q = {}\n",
    "Q_matchingCounts = {}\n",
    "for q in all_qs:\n",
    "    totalReads = 0\n",
    "    notMatching = 0\n",
    "    for refBase, calls in all_reads.items():\n",
    "        #Reads that match the ref base and Q=q\n",
    "        if q in all_reads[refBase][refBase]: totalReads += all_reads[refBase][refBase][q] \n",
    "            \n",
    "        #Reads that don't match the ref base and have Q=q\n",
    "        for base in calls:\n",
    "            if refBase == base: continue #Skip the ref base because these match and already added to total\n",
    "            try: \n",
    "                notMatching += all_reads[refBase][base][q]\n",
    "                totalReads  += all_reads[refBase][base][q]\n",
    "            except:continue #Do nothing there are no reads with that base or that quality\n",
    "            #print (\"\\t\",q,refBase,base,all_reads[refBase][base][q])\n",
    "    Q_matchingCounts[q] = [totalReads-notMatching,notMatching]  # {q:[#reads with Q=q and match ref, #reads with Q=q and do NOT match ref]}\n",
    "    phat_q = notMatching/float(totalReads)\n",
    "    print (\"P_%i = %i / %i = %.8f\" % (q,notMatching,totalReads,phat_q))\n",
    "    Phat_q[q] = phat_q #Store p-hat_q %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Plug all $\\hat{P}_{q}$ into the $L(H_o |  Data )$</h4>\n",
    "<a id=error>What is going on here? Do we have the equation wrong somewhere?</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1300.469745222019"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "921*log(0.24365079)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.844674407370963e+19\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "import sys\n",
    "L_H_o = 1.0\n",
    "nparamsHo = 0\n",
    "for q in all_qs:\n",
    "    nparamsHo += 1\n",
    "    if Phat_q[q] == 0:\n",
    "        L_H_o -= sys.maxsize\n",
    "    else:\n",
    "        notError = Q_matchingCounts[q][0]*log(1-Phat_q[q])\n",
    "        error = Q_matchingCounts[q][1]*log(Phat_q[q])        \n",
    "        L_H_o +=  (notError + error)\n",
    "    #print(\"Q=%i (1-%.8f)^%i * (%.8f)^%i\" % (q,Phat_q[q],Q_matchingCounts[q][0],Phat_q[q],Q_matchingCounts[q][1]))\n",
    "print(L_H_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-89458.96790282137\n"
     ]
    }
   ],
   "source": [
    "L_H_o = 1.0\n",
    "for q in all_qs:\n",
    "    if Phat_q[q] == 0:\n",
    "        pass\n",
    "    else:\n",
    "        notError = Q_matchingCounts[q][0]*log(1-Phat_q[q])\n",
    "        error = Q_matchingCounts[q][1]*log(Phat_q[q])        \n",
    "        L_H_o +=  (notError + error)\n",
    "print(L_H_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Lets work on the $L(H_A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the $\\hat{P}_{BQ}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Ha.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_QBs = {}\n",
    "bases = set(['A','C','G','T'])\n",
    "P_QB_Counts = {}\n",
    "for trueBase in bases:\n",
    "    P_QBs[trueBase] = {}\n",
    "    P_QB_Counts[trueBase] = {}\n",
    "    for q in all_qs:\n",
    "        total_with_q = 0\n",
    "        if q in all_reads[trueBase][trueBase]:total_with_q = all_reads[trueBase][trueBase][q]\n",
    "        dont_Match_True_Base = 0 \n",
    "        for readBase in bases.difference(set([trueBase])):\n",
    "            if q in all_reads[trueBase][readBase]:\n",
    "                dont_Match_True_Base += all_reads[trueBase][readBase][q]\n",
    "                total_with_q += all_reads[trueBase][readBase][q]\n",
    "        try:\n",
    "            P_QBs[trueBase][q] = dont_Match_True_Base / float(total_with_q)\n",
    "            P_QB_Counts[trueBase][q] = [total_with_q-dont_Match_True_Base,dont_Match_True_Base]\n",
    "        except: pass\n",
    "            #print (dont_Match_True_Base,total_with_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.301034833169298e+19\n"
     ]
    }
   ],
   "source": [
    "L_H_a = 0\n",
    "nparamsHa = 0\n",
    "for base in P_QBs:\n",
    "    for q in P_QBs[base]:\n",
    "        nparamsHa += 1\n",
    "        #print (\"P_%s%i = (%i * log(1-%.8f) + %i * log(%.8f))\" % (base, q, P_QB_Counts[base][q][0], P_QBs[base][q], P_QB_Counts[base][q][1], P_QBs[base][q]))\n",
    "        if P_QBs[base][q] == 0:\n",
    "            L_H_a -= sys.maxsize\n",
    "        else:\n",
    "            L_H_a += P_QB_Counts[base][q][0]*log(1-P_QBs[base][q]) + P_QB_Counts[base][q][1]*log(P_QBs[base][q])\n",
    "\n",
    "print(L_H_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22222222222222315\n",
      "3.00815479355254\n",
      "3.4532354319070364e-16\n"
     ]
    }
   ],
   "source": [
    "print(L_H_o/L_H_a)\n",
    "print(-2*log(L_H_o/L_H_a))\n",
    "print(chi2.cdf(-2*log(L_H_o/L_H_a),40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2.cdf(-2*log(i/100.0),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.4877352247211103\n",
      "0.02 0.3539808827649893\n",
      "0.03 0.27579383555931863\n",
      "0.04 0.22275700338771753\n",
      "0.05 0.18402015441380484\n",
      "0.06 0.15441849108098493\n",
      "0.07 0.1310893803953896\n",
      "0.08 0.11228580112754079\n",
      "0.09 0.09686767368182102\n",
      "0.10 0.08405321105610117\n",
      "0.11 0.07328544042501699\n",
      "0.12 0.06415530652119009\n",
      "0.13 0.05635485033441404\n",
      "0.14 0.04964739848814972\n",
      "0.15 0.04384787107283035\n",
      "0.16 0.03880936488369908\n",
      "0.17 0.034413768110536855\n",
      "0.18 0.030565044107492306\n",
      "0.19 0.027184328942561946\n",
      "0.20 0.024206289929415644\n",
      "0.21 0.02157637863487204\n",
      "0.22 0.01924872982784901\n",
      "0.23 0.017184534416371848\n",
      "0.24 0.015350765241468264\n",
      "0.25 0.01371916900076956\n",
      "0.26 0.012265461285807584\n",
      "0.27 0.010968678327053543\n",
      "0.28 0.009810650850556575\n",
      "0.29 0.008775573961959191\n",
      "0.30 0.007849653185919504\n",
      "0.31 0.007020811375544124\n",
      "0.32 0.006278444629162182\n",
      "0.33 0.005613217931468047\n",
      "0.34 0.005016893198424432\n",
      "0.35 0.004482183911013917\n",
      "0.36 0.004002631687589699\n",
      "0.37 0.0035725010522901267\n",
      "0.38 0.0031866893694804483\n",
      "0.39 0.0028406494772070545\n",
      "0.40 0.0025303230003678504\n",
      "0.41 0.002252082682458374\n",
      "0.42 0.0020026823628818283\n",
      "0.43 0.0017792134598451851\n",
      "0.44 0.0015790670082945434\n",
      "0.45 0.0013999004570722858\n",
      "0.46 0.001239608556442813\n",
      "0.47 0.0010962977717699296\n",
      "0.48 0.0009682637457230116\n",
      "0.49 0.0008539714033364654\n",
      "0.50 0.0007520373542519604\n",
      "0.51 0.0006612142966994502\n",
      "0.52 0.0005803771699605399\n",
      "0.53 0.0005085108376109467\n",
      "0.54 0.00044469911389654\n",
      "0.55 0.00038811497108693076\n",
      "0.56 0.0003380117873297243\n",
      "0.57 0.0002937155130189835\n",
      "0.58 0.0002546176495050861\n",
      "0.59 0.00022016894753290188\n",
      "0.60 0.0001898737444515227\n",
      "0.61 0.00016328486928326473\n",
      "0.62 0.00013999905341538255\n",
      "0.63 0.00011965279218838325\n",
      "0.64 0.00010191860917066783\n",
      "0.65 8.650168057408837e-05\n",
      "0.66 7.313678220004109e-05\n",
      "0.67 6.158552561341557e-05\n",
      "0.68 5.1633854008972174e-05\n",
      "0.69 4.308977153541132e-05\n",
      "0.70 3.578128273945544e-05\n",
      "0.71 2.955452133944651e-05\n",
      "0.72 2.4272049781258726e-05\n",
      "0.73 1.9811313008208962e-05\n",
      "0.74 1.6063231625017166e-05\n",
      "0.75 1.2930921182939273e-05\n",
      "0.76 1.0328525684166192e-05\n",
      "0.77 8.18015462024709e-06\n",
      "0.78 6.41891394052525e-06\n",
      "0.79 4.986022308748995e-06\n",
      "0.80 3.830004863376413e-06\n",
      "0.81 2.905957462024332e-06\n",
      "0.82 2.174875073833301e-06\n",
      "0.83 1.603038594676281e-06\n",
      "0.84 1.161454907391923e-06\n",
      "0.85 8.253454998170097e-07\n",
      "0.86 5.736793936827035e-07\n",
      "0.87 3.887465330101781e-07\n",
      "0.88 2.557681364108566e-07\n",
      "0.89 1.6254083799703755e-07\n",
      "0.90 9.911173026457273e-08\n",
      "0.91 5.748168269981649e-08\n",
      "0.92 3.1334544978491226e-08\n",
      "0.93 1.579005611361525e-08\n",
      "0.94 7.178473123107614e-09\n",
      "0.95 2.8351068120826507e-09\n",
      "0.96 9.131099557420791e-10\n",
      "0.97 2.1300617787921672e-10\n",
      "0.98 2.757761926807991e-11\n",
      "0.99 8.473927147733393e-13\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,100):\n",
    "    print(\"%.2f\" % (i/100.0),chi2.cdf(-2*log(i/100.0),10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degrees of Freedom: 239\n"
     ]
    }
   ],
   "source": [
    "degreesOfFreedom = nparamsHa - nparamsHo\n",
    "print (\"Degrees of Freedom:\", degreesOfFreedom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.700928153717132e-182"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "chi2.cdf(-2*log(L_H_o/L_H_a),243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on chi2_gen in module scipy.stats._continuous_distns object:\n",
      "\n",
      "class chi2_gen(scipy.stats._distn_infrastructure.rv_continuous)\n",
      " |  chi2_gen(momtype=1, a=None, b=None, xtol=1e-14, badvalue=None, name=None, longname=None, shapes=None, extradoc=None, seed=None)\n",
      " |  \n",
      " |  A chi-squared continuous random variable.\n",
      " |  \n",
      " |  %(before_notes)s\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The probability density function for `chi2` is:\n",
      " |  \n",
      " |  .. math::\n",
      " |  \n",
      " |      f(x, df) = \\frac{1}{(2 \\gamma(df/2)} (x/2)^{df/2-1} \\exp(-x/2)\n",
      " |  \n",
      " |  `chi2` takes ``df`` as a shape parameter.\n",
      " |  \n",
      " |  %(after_notes)s\n",
      " |  \n",
      " |  %(example)s\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      chi2_gen\n",
      " |      scipy.stats._distn_infrastructure.rv_continuous\n",
      " |      scipy.stats._distn_infrastructure.rv_generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from scipy.stats._distn_infrastructure.rv_continuous:\n",
      " |  \n",
      " |  __init__(self, momtype=1, a=None, b=None, xtol=1e-14, badvalue=None, name=None, longname=None, shapes=None, extradoc=None, seed=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  cdf(self, x, *args, **kwds)\n",
      " |      Cumulative distribution function of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cdf : ndarray\n",
      " |          Cumulative distribution function evaluated at `x`\n",
      " |  \n",
      " |  expect(self, func=None, args=(), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
      " |      Calculate expected value of a function with respect to the\n",
      " |      distribution.\n",
      " |      \n",
      " |      The expected value of a function ``f(x)`` with respect to a\n",
      " |      distribution ``dist`` is defined as::\n",
      " |      \n",
      " |                  ubound\n",
      " |          E[x] = Integral(f(x) * dist.pdf(x))\n",
      " |                  lbound\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, optional\n",
      " |          Function for which integral is calculated. Takes only one argument.\n",
      " |          The default is the identity mapping f(x) = x.\n",
      " |      args : tuple, optional\n",
      " |          Shape parameters of the distribution.\n",
      " |      loc : float, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : float, optional\n",
      " |          Scale parameter (default=1).\n",
      " |      lb, ub : scalar, optional\n",
      " |          Lower and upper bound for integration. Default is set to the\n",
      " |          support of the distribution.\n",
      " |      conditional : bool, optional\n",
      " |          If True, the integral is corrected by the conditional probability\n",
      " |          of the integration interval.  The return value is the expectation\n",
      " |          of the function, conditional on being in the given interval.\n",
      " |          Default is False.\n",
      " |      \n",
      " |      Additional keyword arguments are passed to the integration routine.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      expect : float\n",
      " |          The calculated expected value.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The integration behavior of this function is inherited from\n",
      " |      `integrate.quad`.\n",
      " |  \n",
      " |  fit(self, data, *args, **kwds)\n",
      " |      Return MLEs for shape (if applicable), location, and scale\n",
      " |      parameters from data.\n",
      " |      \n",
      " |      MLE stands for Maximum Likelihood Estimate.  Starting estimates for\n",
      " |      the fit are given by input arguments; for any arguments not provided\n",
      " |      with starting estimates, ``self._fitstart(data)`` is called to generate\n",
      " |      such.\n",
      " |      \n",
      " |      One can hold some parameters fixed to specific values by passing in\n",
      " |      keyword arguments ``f0``, ``f1``, ..., ``fn`` (for shape parameters)\n",
      " |      and ``floc`` and ``fscale`` (for location and scale parameters,\n",
      " |      respectively).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : array_like\n",
      " |          Data to use in calculating the MLEs.\n",
      " |      args : floats, optional\n",
      " |          Starting value(s) for any shape-characterizing arguments (those not\n",
      " |          provided will be determined by a call to ``_fitstart(data)``).\n",
      " |          No default value.\n",
      " |      kwds : floats, optional\n",
      " |          Starting values for the location and scale parameters; no default.\n",
      " |          Special keyword arguments are recognized as holding certain\n",
      " |          parameters fixed:\n",
      " |      \n",
      " |          - f0...fn : hold respective shape parameters fixed.\n",
      " |            Alternatively, shape parameters to fix can be specified by name.\n",
      " |            For example, if ``self.shapes == \"a, b\"``, ``fa``and ``fix_a``\n",
      " |            are equivalent to ``f0``, and ``fb`` and ``fix_b`` are\n",
      " |            equivalent to ``f1``.\n",
      " |      \n",
      " |          - floc : hold location parameter fixed to specified value.\n",
      " |      \n",
      " |          - fscale : hold scale parameter fixed to specified value.\n",
      " |      \n",
      " |          - optimizer : The optimizer to use.  The optimizer must take ``func``,\n",
      " |            and starting position as the first two arguments,\n",
      " |            plus ``args`` (for extra arguments to pass to the\n",
      " |            function to be optimized) and ``disp=0`` to suppress\n",
      " |            output as keyword arguments.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mle_tuple : tuple of floats\n",
      " |          MLEs for any shape parameters (if applicable), followed by those\n",
      " |          for location and scale. For most random variables, shape statistics\n",
      " |          will be returned, but there are exceptions (e.g. ``norm``).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This fit is computed by maximizing a log-likelihood function, with\n",
      " |      penalty applied for samples outside of range of the distribution. The\n",
      " |      returned answer is not guaranteed to be the globally optimal MLE, it\n",
      " |      may only be locally optimal, or the optimization may fail altogether.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Generate some data to fit: draw random variates from the `beta`\n",
      " |      distribution\n",
      " |      \n",
      " |      >>> from scipy.stats import beta\n",
      " |      >>> a, b = 1., 2.\n",
      " |      >>> x = beta.rvs(a, b, size=1000)\n",
      " |      \n",
      " |      Now we can fit all four parameters (``a``, ``b``, ``loc`` and ``scale``):\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x)\n",
      " |      \n",
      " |      We can also use some prior knowledge about the dataset: let's keep\n",
      " |      ``loc`` and ``scale`` fixed:\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x, floc=0, fscale=1)\n",
      " |      >>> loc1, scale1\n",
      " |      (0, 1)\n",
      " |      \n",
      " |      We can also keep shape parameters fixed by using ``f``-keywords. To\n",
      " |      keep the zero-th shape parameter ``a`` equal 1, use ``f0=1`` or,\n",
      " |      equivalently, ``fa=1``:\n",
      " |      \n",
      " |      >>> a1, b1, loc1, scale1 = beta.fit(x, fa=1, floc=0, fscale=1)\n",
      " |      >>> a1\n",
      " |      1\n",
      " |      \n",
      " |      Not all distributions return estimates for the shape parameters.\n",
      " |      ``norm`` for example just returns estimates for location and scale:\n",
      " |      \n",
      " |      >>> from scipy.stats import norm\n",
      " |      >>> x = norm.rvs(a, b, size=1000, random_state=123)\n",
      " |      >>> loc1, scale1 = norm.fit(x)\n",
      " |      >>> loc1, scale1\n",
      " |      (0.92087172783841631, 2.0015750750324668)\n",
      " |  \n",
      " |  fit_loc_scale(self, data, *args)\n",
      " |      Estimate loc and scale parameters from data using 1st and 2nd moments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : array_like\n",
      " |          Data to fit.\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Lhat : float\n",
      " |          Estimated location parameter for the data.\n",
      " |      Shat : float\n",
      " |          Estimated scale parameter for the data.\n",
      " |  \n",
      " |  isf(self, q, *args, **kwds)\n",
      " |      Inverse survival function (inverse of `sf`) at q of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : array_like\n",
      " |          upper tail probability\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      x : ndarray or scalar\n",
      " |          Quantile corresponding to the upper tail probability q.\n",
      " |  \n",
      " |  logcdf(self, x, *args, **kwds)\n",
      " |      Log of the cumulative distribution function at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logcdf : array_like\n",
      " |          Log of the cumulative distribution function evaluated at x\n",
      " |  \n",
      " |  logpdf(self, x, *args, **kwds)\n",
      " |      Log of the probability density function at x of the given RV.\n",
      " |      \n",
      " |      This uses a more numerically accurate calculation if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logpdf : array_like\n",
      " |          Log of the probability density function evaluated at x\n",
      " |  \n",
      " |  logsf(self, x, *args, **kwds)\n",
      " |      Log of the survival function of the given RV.\n",
      " |      \n",
      " |      Returns the log of the \"survival function,\" defined as (1 - `cdf`),\n",
      " |      evaluated at `x`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logsf : ndarray\n",
      " |          Log of the survival function evaluated at `x`.\n",
      " |  \n",
      " |  nnlf(self, theta, x)\n",
      " |      Return negative loglikelihood function.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is ``-sum(log pdf(x, theta), axis=0)`` where `theta` are the\n",
      " |      parameters (including loc and scale).\n",
      " |  \n",
      " |  pdf(self, x, *args, **kwds)\n",
      " |      Probability density function at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pdf : ndarray\n",
      " |          Probability density function evaluated at x\n",
      " |  \n",
      " |  ppf(self, q, *args, **kwds)\n",
      " |      Percent point function (inverse of `cdf`) at q of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : array_like\n",
      " |          lower tail probability\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      x : array_like\n",
      " |          quantile corresponding to the lower tail probability q.\n",
      " |  \n",
      " |  sf(self, x, *args, **kwds)\n",
      " |      Survival function (1 - `cdf`) at x of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          quantiles\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sf : array_like\n",
      " |          Survival function evaluated at x\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.stats._distn_infrastructure.rv_generic:\n",
      " |  \n",
      " |  __call__(self, *args, **kwds)\n",
      " |      Freeze the distribution for the given arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution.  Should include all\n",
      " |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rv_frozen : rv_frozen instance\n",
      " |          The frozen distribution.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  entropy(self, *args, **kwds)\n",
      " |      Differential entropy of the RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : array_like, optional  (continuous distributions only).\n",
      " |          Scale parameter (default=1).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Entropy is defined base `e`:\n",
      " |      \n",
      " |      >>> drv = rv_discrete(values=((0, 1), (0.5, 0.5)))\n",
      " |      >>> np.allclose(drv.entropy(), np.log(2.0))\n",
      " |      True\n",
      " |  \n",
      " |  freeze(self, *args, **kwds)\n",
      " |      Freeze the distribution for the given arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution.  Should include all\n",
      " |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rv_frozen : rv_frozen instance\n",
      " |          The frozen distribution.\n",
      " |  \n",
      " |  interval(self, alpha, *args, **kwds)\n",
      " |      Confidence interval with equal areas around the median.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      alpha : array_like of float\n",
      " |          Probability that an rv will be drawn from the returned range.\n",
      " |          Each value should be in the range [0, 1].\n",
      " |      arg1, arg2, ... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          location parameter, Default is 0.\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter, Default is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a, b : ndarray of float\n",
      " |          end-points of range that contain ``100 * alpha %`` of the rv's\n",
      " |          possible values.\n",
      " |  \n",
      " |  mean(self, *args, **kwds)\n",
      " |      Mean of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : float\n",
      " |          the mean of the distribution\n",
      " |  \n",
      " |  median(self, *args, **kwds)\n",
      " |      Median of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter, Default is 0.\n",
      " |      scale : array_like, optional\n",
      " |          Scale parameter, Default is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : float\n",
      " |          The median of the distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      stats.distributions.rv_discrete.ppf\n",
      " |          Inverse of the CDF\n",
      " |  \n",
      " |  moment(self, n, *args, **kwds)\n",
      " |      n-th order non-central moment of distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, n >= 1\n",
      " |          Order of moment.\n",
      " |      arg1, arg2, arg3,... : float\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |  \n",
      " |  rvs(self, *args, **kwds)\n",
      " |      Random variates of given type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information).\n",
      " |      loc : array_like, optional\n",
      " |          Location parameter (default=0).\n",
      " |      scale : array_like, optional\n",
      " |          Scale parameter (default=1).\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Defining number of random variates (default is 1).\n",
      " |      random_state : None or int or ``np.random.RandomState`` instance, optional\n",
      " |          If int or RandomState, use it for drawing the random variates.\n",
      " |          If None, rely on ``self.random_state``.\n",
      " |          Default is None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      rvs : ndarray or scalar\n",
      " |          Random variates of given `size`.\n",
      " |  \n",
      " |  stats(self, *args, **kwds)\n",
      " |      Some statistics of the given RV.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional (continuous RVs only)\n",
      " |          scale parameter (default=1)\n",
      " |      moments : str, optional\n",
      " |          composed of letters ['mvsk'] defining which moments to compute:\n",
      " |          'm' = mean,\n",
      " |          'v' = variance,\n",
      " |          's' = (Fisher's) skew,\n",
      " |          'k' = (Fisher's) kurtosis.\n",
      " |          (default is 'mv')\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stats : sequence\n",
      " |          of requested moments.\n",
      " |  \n",
      " |  std(self, *args, **kwds)\n",
      " |      Standard deviation of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : float\n",
      " |          standard deviation of the distribution\n",
      " |  \n",
      " |  var(self, *args, **kwds)\n",
      " |      Variance of the distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg1, arg2, arg3,... : array_like\n",
      " |          The shape parameter(s) for the distribution (see docstring of the\n",
      " |          instance object for more information)\n",
      " |      loc : array_like, optional\n",
      " |          location parameter (default=0)\n",
      " |      scale : array_like, optional\n",
      " |          scale parameter (default=1)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : float\n",
      " |          the variance of the distribution\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.stats._distn_infrastructure.rv_generic:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  random_state\n",
      " |      Get or set the RandomState object for generating random variates.\n",
      " |      \n",
      " |      This can be either None or an existing RandomState object.\n",
      " |      \n",
      " |      If None (or np.random), use the RandomState singleton used by np.random.\n",
      " |      If already a RandomState instance, use it.\n",
      " |      If an int, use a new RandomState instance seeded with seed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{64: 197, 65: 2538, 66: 4219, 67: 3592, 63: 210, 62: 156, 68: 601, 69: 54, 49: 198, 51: 106}\n"
     ]
    }
   ],
   "source": [
    "tester={}\n",
    "data = ProcessPosition(768)\n",
    "for read in data.reads[1]:\n",
    "    try:tester[read.q] += 1\n",
    "    except:tester[read.q] = 1\n",
    "print(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6158.9693702291115"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ProcessPosition(964)\n",
    "data.callMatchRef[ind]\n",
    "data.errorProbs[ind]\n",
    "rfuncts.log_likelihood_MAP(1,rArray(data.callMatchRef[ind]),2,rArray(data.errorProbs[ind]),data.total_reads[ind])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(\"data/I0_Pos962_data.txt\",\"w\")\n",
    "fh.write(\"i\\tj\\tq\\ta\\n\")\n",
    "nRead = 0\n",
    "data = ProcessPosition(962)\n",
    "for read in data.reads[0]: \n",
    "    nRead +=1\n",
    "    fh.write(\"0\\t%i\\t%i\\t%i\\n\" % (nRead,read.q,int(read.call == data.majorAllele)))\n",
    "fh.close()\n",
    "fh = open(\"data/I0_Pos768_data.txt\",\"w\")\n",
    "fh.write(\"i\\tj\\tq\\ta\\n\")\n",
    "nRead = 0\n",
    "data = ProcessPosition(768)\n",
    "for read in data.reads[0]: \n",
    "    nRead +=1\n",
    "    fh.write(\"0\\t%i\\t%i\\t%i\\n\" % (nRead,read.q,int(read.call == data.majorAllele)))\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4827\n",
      "{'A': 4044, 'C': 3, 'G': 4827, 'T': 9}\n",
      "8869\n",
      "{'A': 2, 'C': 2, 'G': 8869, 'T': 2}\n"
     ]
    }
   ],
   "source": [
    "data = ProcessPosition(962)\n",
    "print(data.read_counter[0][data.majorAllele])\n",
    "print(data.read_counter[0])\n",
    "data = ProcessPosition(768)\n",
    "print(data.read_counter[0][data.majorAllele])\n",
    "print(data.read_counter[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for fhName in [\"data/Pos962_data.txt\",\"data/Pos964_data.txt\"]:\n",
    "    fh = open(fhName,\"w\")\n",
    "    fh.write(\"i\\tj\\tq\\ta\\n\")\n",
    "    nRead = 0\n",
    "    for read in positions[count]: \n",
    "        nRead +=1\n",
    "        fh.write(\"0\\t%i\\t%i\\t%i\\n\" % (nRead,read.q,int(read.call == 'A')))\n",
    "    fh.close()\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 "
     ]
    }
   ],
   "source": [
    "ProcessPosition(764)\n",
    "nuc_counter = {'A':0.0, 'C':0.0, 'G':0.0, 'T':0.0}\n",
    "sumErrors ={0:nuc_counter.copy(),1:nuc_counter.copy(),2:nuc_counter.copy()}\n",
    "\n",
    "for pos in range(765,1200):\n",
    "    print (pos, end=\" \")\n",
    "    data = ProcessPosition(pos)\n",
    "    for ind in data:\n",
    "        for read in data.reads[ind]: sumErrors[ind][read.call]+= read.errorProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base: A 3429.1776508600797\n",
      "Base: C 2259.211534865086\n",
      "Base: G 2182.5860077850057\n",
      "Base: T 3262.2079794843016\n"
     ]
    }
   ],
   "source": [
    "for base in nuc_counter:\n",
    "    print(\"Base:\",base,end=\" \")\n",
    "    total = 0.0\n",
    "    for ind in sumErrors:total += sumErrors[ind][base]\n",
    "    print (total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Locus at 0x2b4dee43e128>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from pandas import DataFrame\n",
    "# dataLayout = DataFrame(dataLayout)\n",
    "# for base in data[0]:\n",
    "#     print(dataLayout.)\n",
    "data = ProcessPosition(942)\n",
    "data.\n",
    "# dataLayout[\"Itotal\"] = dataLayout.sum()\n",
    "# dataLayout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
